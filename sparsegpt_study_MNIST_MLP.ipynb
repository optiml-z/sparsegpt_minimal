{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\igor-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_runtime.py:185: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from modelutils import *\n",
    "from quant import *\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DEBUG = True \n",
    "\n",
    "@dataclass\n",
    "class Args(object):\n",
    "    nsamples: int = 16\n",
    "    sparsity = 0.3\n",
    "    prunen: int = 0\n",
    "    prunem: int = 0\n",
    "    percdamp = .01\n",
    "    blocksize: int = 16\n",
    "    batch_size: int = 16\n",
    "    num_layers: int = 5\n",
    "    num_blocks: int = 4\n",
    "    input_size: int = 784\n",
    "    output_size: int = 10\n",
    "    minlayer: int = -1\n",
    "    maxlayer: int = 1000\n",
    "    prune_only: str = \"\"\n",
    "    invert: bool = False\n",
    "args = Args()\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preparation\n",
    "# Define transformations and load datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "# Confirm if data is loaded\n",
    "len(trainset), len(testset)\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCBlock(nn.Module):\n",
    "    def __init__(self, input_size = 28*28, output_size = 28*28, num_layers = 4):\n",
    "        super(FCBlock, self).__init__()\n",
    "        # self.fc_layers = nn.Sequential(\n",
    "        #     *([nn.Linear(input_size, output_size), nn.ReLU()]*num_layers) \n",
    "        # )        \n",
    "        # self.fc_layers = [nn.Linear(input_size, output_size) for _ in range(num_layers)]\n",
    "        # self.fc_layers = nn.ModuleList(self.fc_layers)\n",
    "        # self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(output_size, output_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # self.fc_layers = nn.Sequential(*[nn.ReLU(nn.Linear(input_size, output_size)) for _ in range(num_layers)])    \n",
    "    def forward(self, x):\n",
    "        # for layer in self.fc_layers:\n",
    "        #     x = layer(x)\n",
    "        #     x = self.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        # self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=28*28, output_size=10, num_blocks = 4, num_layers = 4):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.blocks = [FCBlock(num_layers = num_layers) for _ in range(num_blocks)]\n",
    "        out = nn.Linear(input_size, output_size)\n",
    "        self.blocks.append(out)\n",
    "        self.blocks = nn.ModuleList(self.blocks)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        for fcblock in self.blocks[:-1]:\n",
    "            x = fcblock(x)\n",
    "        x = self.blocks[-1](x)\n",
    "        return x\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(MLP2, self).__init__()\n",
    "        # Create a list of fully connected layers based on the sizes provided\n",
    "\n",
    "        layers = [nn.Linear(input_size, hidden_sizes[0]), nn.ReLU()]\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        # Unpack the layers list into nn.Sequential, which will manage the layers for us\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        # Normalization layers, assuming we want to apply these at the end of the network\n",
    "        self.norm = nn.LayerNorm(output_size, elementwise_affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, args.input_size)\n",
    "        x = self.layers(x)\n",
    "        x = self.norm(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "input_size = args.input_size\n",
    "hidden_sizes = [args.input_size]*args.num_layers  # Example layer sizes, similar to what's shown in the image\n",
    "output_size = args.output_size\n",
    "model = MLP2(input_size, hidden_sizes, output_size).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DynamicMLP(num_layers=args.num_layers).to(device)\n",
    "# model = BlockDynamicMLP(input_size=28*28, output_size=10, num_blocks=4, num_layers=args.num_layers).to(device)\n",
    "model = MLP(num_blocks = args.num_blocks, num_layers = args.num_layers).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 2\n",
    "train_losses, test_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP2(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=784, out_features=10, bias=True)\n",
       "  )\n",
       "  (norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP2(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=784, out_features=10, bias=True)\n",
       "  )\n",
       "  (norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers.0': Linear(in_features=784, out_features=784, bias=True),\n",
       " 'layers.2': Linear(in_features=784, out_features=784, bias=True),\n",
       " 'layers.4': Linear(in_features=784, out_features=784, bias=True),\n",
       " 'layers.6': Linear(in_features=784, out_features=784, bias=True),\n",
       " 'layers.8': Linear(in_features=784, out_features=784, bias=True),\n",
       " 'layers.10': Linear(in_features=784, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_dict = find_layers(model)\n",
    "layers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"block_dynamic_mnist_mlp.pth\"\n",
    "LOAD = False\n",
    "\n",
    "if not(LOAD):\n",
    "    SAVE = True\n",
    "else:\n",
    "    SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2.. Train loss: 0.688.. Test loss: 0.257.. Test accuracy: 0.926\n",
      "Epoch 2/2.. Train loss: 0.212.. Test loss: 0.201.. Test accuracy: 0.945\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if LOAD:\n",
    "    PATH = f'./{MODEL_NAME}'\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "else:    \n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images.to(device))\n",
    "            loss = criterion(output, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        else:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in testloader:\n",
    "                    log_ps = model(images.to(device))\n",
    "                    test_loss += criterion(log_ps, labels.to(device))\n",
    "                    ps = torch.exp(log_ps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.to(device).view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                    \n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "            print(f\"Epoch {e+1}/{epochs}.. \"\n",
    "                f\"Train loss: {running_loss/len(trainloader):.3f}.. \"\n",
    "                f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "\n",
    "    print('Finished Training')\n",
    "    if SAVE:\n",
    "        PATH = f'./{MODEL_NAME}'\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        plt.plot(train_losses, label='Training loss')\n",
    "        plt.plot(list(map(torch.Tensor.cpu, test_losses)), label='Validation loss')\n",
    "        plt.legend(frameon=False)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples tested = 1000\n",
      "\n",
      "Model Accuracy = 0.944\n"
     ]
    }
   ],
   "source": [
    "def infer_and_compute_accuracy_random_samples(model, dataset, num_samples=1000):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    # Create a list of indices and shuffle them\n",
    "    indices = list(range(len(dataset)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num_samples]\n",
    "\n",
    "    # Create a DataLoader with SubsetRandomSampler\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    testloader_random_samples = DataLoader(dataset, batch_size=args.batch_size, sampler=sampler)\n",
    "\n",
    "    correct_count, all_count = 0, 0\n",
    "    for images, labels in testloader_random_samples:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images.view(images.shape[0], -1).to(device))\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_count += (predicted == labels.to(device)).sum().item()\n",
    "        all_count += labels.size(0)\n",
    "    \n",
    "    print(\"Number of Samples tested =\", all_count)\n",
    "    print(\"\\nModel Accuracy =\", (correct_count / all_count))\n",
    "\n",
    "# Assuming testset is your test dataset\n",
    "# Call the function\n",
    "infer_and_compute_accuracy_random_samples(model, testset, num_samples=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1](torch.randn(1, 28*28).to(device)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=784, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=784, out_features=784, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=784, out_features=784, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=784, out_features=784, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Linear(in_features=784, out_features=784, bias=True)\n",
       "  (9): ReLU()\n",
       "  (10): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers.0': Linear(in_features=784, out_features=784, bias=True),\n",
       " 'layers.2': Linear(in_features=784, out_features=784, bias=True),\n",
       " 'layers.4': Linear(in_features=784, out_features=784, bias=True),\n",
       " 'layers.6': Linear(in_features=784, out_features=784, bias=True),\n",
       " 'layers.8': Linear(in_features=784, out_features=784, bias=True),\n",
       " 'layers.10': Linear(in_features=784, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_dict = find_layers(model)\n",
    "layers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseGPT:\n",
    "\n",
    "    def __init__(self, layer):\n",
    "        self.layer = layer\n",
    "        print(layer)\n",
    "        print(type(layer))\n",
    "        self.dev = self.layer.weight.device\n",
    "        W = layer.weight.data.clone()\n",
    "        if isinstance(self.layer, nn.Conv2d):\n",
    "            W = W.flatten(1)\n",
    "        if isinstance(self.layer, transformers.Conv1D):\n",
    "            W = W.t()\n",
    "        self.rows = W.shape[0]\n",
    "        self.columns = W.shape[1]\n",
    "        self.H = torch.zeros((self.columns, self.columns), device=self.dev)\n",
    "        self.nsamples = 0\n",
    "\n",
    "    def add_batch(self, inp, out, blocksize=args.blocksize):\n",
    "        if DEBUG:\n",
    "            self.inp1 = inp\n",
    "            self.out1 = out\n",
    "        if len(inp.shape) == 2:\n",
    "            inp = inp.unsqueeze(0)\n",
    "        tmp = inp.shape[0]\n",
    "        if isinstance(self.layer, nn.Linear) or isinstance(self.layer, transformers.Conv1D):\n",
    "            if len(inp.shape) == 3:\n",
    "                inp = inp.reshape((-1, inp.shape[-1]))\n",
    "            inp = inp.t()\n",
    "        self.H *= self.nsamples / (self.nsamples + tmp)\n",
    "        self.nsamples += tmp\n",
    "        inp = math.sqrt(2 / self.nsamples) * inp.float()\n",
    "        self.H += inp.matmul(inp.t())\n",
    "\n",
    "    def fasterprune(\n",
    "        self, sparsity, prunen=0, prunem=0, blocksize=args.blocksize, percdamp=.01\n",
    "    ):\n",
    "        W = self.layer.weight.data.clone()\n",
    "        if isinstance(self.layer, nn.Conv2d):\n",
    "            W = W.flatten(1)\n",
    "        if isinstance(self.layer, transformers.Conv1D):\n",
    "            W = W.t()\n",
    "        W = W.float()\n",
    "\n",
    "        if hasattr(self, 'quantizer'):\n",
    "            if not self.quantizer.ready():\n",
    "                self.quantizer.find_params(W, weight=True)\n",
    "\n",
    "        tick = time.time()\n",
    "\n",
    "        H = self.H\n",
    "        del self.H\n",
    "        dead = torch.diag(H) == 0\n",
    "        H[dead, dead] = 1\n",
    "        W[:, dead] = 0\n",
    "\n",
    "        Losses = torch.zeros(self.rows, device=self.dev)\n",
    "\n",
    "        damp = percdamp * torch.mean(torch.diag(H))\n",
    "        diag = torch.arange(self.columns, device=self.dev)\n",
    "        H[diag, diag] += damp\n",
    "        H = torch.linalg.cholesky(H)\n",
    "        H = torch.cholesky_inverse(H)\n",
    "        H = torch.linalg.cholesky(H, upper=True)\n",
    "        Hinv = H\n",
    "\n",
    "        mask = None\n",
    "\n",
    "        for i1 in range(0, self.columns, blocksize):\n",
    "            i2 = min(i1 + blocksize, self.columns)\n",
    "            count = i2 - i1\n",
    "\n",
    "            W1 = W[:, i1:i2].clone()\n",
    "            Q1 = torch.zeros_like(W1)\n",
    "            Err1 = torch.zeros_like(W1)\n",
    "            Losses1 = torch.zeros_like(W1)\n",
    "            Hinv1 = Hinv[i1:i2, i1:i2]\n",
    "\n",
    "            if prunen == 0: \n",
    "                if mask is not None:\n",
    "                    mask1 = mask[:, i1:i2]\n",
    "                else:\n",
    "                    tmp = W1 ** 2 / (torch.diag(Hinv1).reshape((1, -1))) ** 2\n",
    "                    thresh = torch.sort(tmp.flatten())[0][int(tmp.numel() * sparsity)]\n",
    "                    mask1 = tmp <= thresh\n",
    "            else:\n",
    "                mask1 = torch.zeros_like(W1) == 1\n",
    "\n",
    "            for i in range(count):\n",
    "                w = W1[:, i]\n",
    "                d = Hinv1[i, i]\n",
    "\n",
    "                if prunen != 0 and i % prunem == 0:\n",
    "                    tmp = W1[:, i:(i + prunem)] ** 2 / (torch.diag(Hinv1)[i:(i + prunem)].reshape((1, -1))) ** 2\n",
    "                    mask1.scatter_(1, i + torch.topk(tmp, prunen, dim=1, largest=False)[1], True)\n",
    "\n",
    "                q = w.clone()\n",
    "                q[mask1[:, i]] = 0\n",
    "\n",
    "                if hasattr(self, 'quantizer'):\n",
    "                    q = quantize(\n",
    "                        q.unsqueeze(1), self.quantizer.scale, self.quantizer.zero, self.quantizer.maxq\n",
    "                    ).flatten()\n",
    "\n",
    "                Q1[:, i] = q\n",
    "                Losses1[:, i] = (w - q) ** 2 / d ** 2\n",
    "\n",
    "                err1 = (w - q) / d\n",
    "                W1[:, i:] -= err1.unsqueeze(1).matmul(Hinv1[i, i:].unsqueeze(0))\n",
    "                Err1[:, i] = err1\n",
    "\n",
    "            W[:, i1:i2] = Q1\n",
    "            Losses += torch.sum(Losses1, 1) / 2\n",
    "\n",
    "            W[:, i2:] -= Err1.matmul(Hinv[i1:i2, i2:])\n",
    "\n",
    "            if DEBUG:\n",
    "                self.layer.weight.data[:, :i2] = W[:, :i2]\n",
    "                self.layer.weight.data[:, i2:] = W[:, i2:]\n",
    "                print(torch.sum((self.layer(self.inp1) - self.out1) ** 2))\n",
    "                print(torch.sum(Losses))\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        print('time %.2f' % (time.time() - tick))\n",
    "        print('error', torch.sum(Losses).item())\n",
    "\n",
    "        if isinstance(self.layer, transformers.Conv1D):\n",
    "            W = W.t()\n",
    "        self.layer.weight.data = W.reshape(self.layer.weight.shape).to(self.layer.weight.data.dtype)\n",
    "        if DEBUG:\n",
    "            print(torch.sum((self.layer(self.inp1) - self.out1) ** 2))\n",
    "\n",
    "    def free(self):\n",
    "        if DEBUG:\n",
    "            self.inp1 = None\n",
    "            self.out1 = None\n",
    "        self.H = None\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(testset)))\n",
    "np.random.shuffle(indices)\n",
    "idx = indices\n",
    "# sampler = SubsetRandomSampler(idx)\n",
    "# calibration_loader = DataLoader(testset, batch_size=args.nsamples, sampler=sampler)\n",
    "calibration_loader = DataLoader(testset, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = MLP(num_blocks = args.num_layers).to(device)\n",
    "model = MLP2(input_size, hidden_sizes, output_size).to(device)\n",
    "model.load_state_dict(torch.load(f\"./{MODEL_NAME}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def mlp_sequential(model, dataloader, dev):\n",
    "    print('Starting ...')\n",
    "\n",
    "    # use_cache = model.config.use_cache\n",
    "    # model.config.use_cache = False\n",
    "    # layers = model.transformer.h\n",
    "    layers = model.layers\n",
    "    print(\"layers: \", layers)\n",
    "    # model.transformer.word_embeddings = model.transformer.word_embeddings.to(dev)\n",
    "    # model.transformer.word_embeddings_layernorm = model.transformer.word_embeddings_layernorm.to(dev)\n",
    "    layers[0] = layers[0].to(dev)\n",
    "    \n",
    "    print(\"layers[0]: \", layers[0])\n",
    "    layers[0] = layers[0].to(dev)\n",
    "\n",
    "    dtype = next(iter(model.parameters())).dtype\n",
    "    inps = torch.zeros(\n",
    "        (args.nsamples, args.nsamples, 28*28), dtype=dtype, device=dev\n",
    "    )\n",
    "    # cache = {'i': 0, 'attention_mask': None, 'alibi': None}\n",
    "    cache = {'i': 0}\n",
    "\n",
    "    class Catcher(nn.Module):\n",
    "        def __init__(self, module):\n",
    "            super().__init__()\n",
    "            self.module = module\n",
    "        def forward(self, inp, **kwargs):\n",
    "            # print(\"inps cache: \", inps[cache['i']])\n",
    "            # if cache['i'] == args.nsamples - 1:\n",
    "            #     raise ValueError\n",
    "            if cache['i'] < args.nsamples:\n",
    "                inps[cache['i']] = inp\n",
    "                cache['i'] += 1\n",
    "            # cache['attention_mask'] = kwargs['attention_mask']\n",
    "            # cache['alibi'] = kwargs['alibi']\n",
    "            raise ValueError\n",
    "    layers[0] = Catcher(layers[0])\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        try:\n",
    "            print(i)\n",
    "            # print(batch[0].shape)\n",
    "            model(batch[0].to(dev))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    layers[0] = layers[0].module\n",
    "\n",
    "    layers[0] = layers[0].cpu()\n",
    "    # model.transformer.word_embeddings = model.transformer.word_embeddings.cpu()\n",
    "    # model.transformer.word_embeddings_layernorm = model.transformer.word_embeddings_layernorm.cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    outs = torch.zeros_like(inps)\n",
    "    # attention_mask = cache['attention_mask']\n",
    "    # alibi = cache['alibi']\n",
    "\n",
    "    print('Ready.')\n",
    "\n",
    "    for i in range(len(layers)-1):\n",
    "        layer = layers[i].to(dev)\n",
    "        print(i, \" \", layer)\n",
    "        subset = find_layers(layer)\n",
    "        gpts = {}\n",
    "        print(gpts)\n",
    "        for name in subset:\n",
    "            if (not (args.minlayer <= i < args.maxlayer and args.prune_only in name)) == (not args.invert):\n",
    "                continue\n",
    "            # elif isinstance(subset[name], nn.Linear) and subset[name].out_features == 10:\n",
    "            #     continue\n",
    "            gpts[name] = SparseGPT(subset[name])\n",
    "\n",
    "        def add_batch(name):\n",
    "            def tmp(_, inp, out):\n",
    "                gpts[name].add_batch(inp[0].data, out.data)\n",
    "            return tmp\n",
    "        handles = []\n",
    "        for name in gpts:\n",
    "            handles.append(subset[name].register_forward_hook(add_batch(name)))\n",
    "        for j in range(args.nsamples):\n",
    "            # outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask, alibi=alibi)[0]\n",
    "            outs[j] = layer(inps[j].unsqueeze(0))[0]\n",
    "        for h in handles:\n",
    "            h.remove()\n",
    "\n",
    "        for name in gpts:\n",
    "            print(i, name)\n",
    "            print('pruning ...')\n",
    "            gpts[name].fasterprune(\n",
    "                args.sparsity, prunen=args.prunen, prunem=args.prunem, percdamp=args.percdamp\n",
    "            )\n",
    "        for j in range(args.nsamples):\n",
    "            # outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask, alibi=alibi)[0]\n",
    "            outs[j] = layer(inps[j].unsqueeze(0))[0]\n",
    "\n",
    "        layers[i] = layer.cpu()\n",
    "        del gpts \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        inps, outs = outs, inps\n",
    "\n",
    "    # model.config.use_cache = use_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ...\n",
      "layers:  Sequential(\n",
      "  (0): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (9): ReLU()\n",
      "  (10): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "layers[0]:  Linear(in_features=784, out_features=784, bias=True)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "Ready.\n",
      "0   Linear(in_features=784, out_features=784, bias=True)\n",
      "{}\n",
      "Linear(in_features=784, out_features=784, bias=True)\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "0 \n",
      "pruning ...\n",
      "tensor(3.1318e-06, device='cuda:0')\n",
      "tensor(0.0321, device='cuda:0')\n",
      "tensor(6.4959e-06, device='cuda:0')\n",
      "tensor(0.0619, device='cuda:0')\n",
      "tensor(5.0960e-05, device='cuda:0')\n",
      "tensor(0.0933, device='cuda:0')\n",
      "tensor(5.7037e-05, device='cuda:0')\n",
      "tensor(0.1243, device='cuda:0')\n",
      "tensor(0.0008, device='cuda:0')\n",
      "tensor(0.1563, device='cuda:0')\n",
      "tensor(0.0011, device='cuda:0')\n",
      "tensor(0.1883, device='cuda:0')\n",
      "tensor(0.0045, device='cuda:0')\n",
      "tensor(0.2274, device='cuda:0')\n",
      "tensor(0.0076, device='cuda:0')\n",
      "tensor(0.2750, device='cuda:0')\n",
      "tensor(0.0101, device='cuda:0')\n",
      "tensor(0.3209, device='cuda:0')\n",
      "tensor(0.0270, device='cuda:0')\n",
      "tensor(0.4035, device='cuda:0')\n",
      "tensor(0.0300, device='cuda:0')\n",
      "tensor(0.4450, device='cuda:0')\n",
      "tensor(0.0634, device='cuda:0')\n",
      "tensor(0.5760, device='cuda:0')\n",
      "tensor(0.0681, device='cuda:0')\n",
      "tensor(0.6253, device='cuda:0')\n",
      "tensor(0.0875, device='cuda:0')\n",
      "tensor(0.7226, device='cuda:0')\n",
      "tensor(0.1034, device='cuda:0')\n",
      "tensor(0.8059, device='cuda:0')\n",
      "tensor(0.1128, device='cuda:0')\n",
      "tensor(0.8681, device='cuda:0')\n",
      "tensor(0.1639, device='cuda:0')\n",
      "tensor(1.0064, device='cuda:0')\n",
      "tensor(0.1684, device='cuda:0')\n",
      "tensor(1.0525, device='cuda:0')\n",
      "tensor(0.2172, device='cuda:0')\n",
      "tensor(1.2070, device='cuda:0')\n",
      "tensor(0.2228, device='cuda:0')\n",
      "tensor(1.2588, device='cuda:0')\n",
      "tensor(0.2532, device='cuda:0')\n",
      "tensor(1.3630, device='cuda:0')\n",
      "tensor(0.2751, device='cuda:0')\n",
      "tensor(1.4531, device='cuda:0')\n",
      "tensor(0.2873, device='cuda:0')\n",
      "tensor(1.5134, device='cuda:0')\n",
      "tensor(0.3560, device='cuda:0')\n",
      "tensor(1.6863, device='cuda:0')\n",
      "tensor(0.3655, device='cuda:0')\n",
      "tensor(1.7384, device='cuda:0')\n",
      "tensor(0.5112, device='cuda:0')\n",
      "tensor(1.9796, device='cuda:0')\n",
      "tensor(0.5292, device='cuda:0')\n",
      "tensor(2.0432, device='cuda:0')\n",
      "tensor(0.6132, device='cuda:0')\n",
      "tensor(2.1879, device='cuda:0')\n",
      "tensor(0.6522, device='cuda:0')\n",
      "tensor(2.3059, device='cuda:0')\n",
      "tensor(0.6706, device='cuda:0')\n",
      "tensor(2.3755, device='cuda:0')\n",
      "tensor(0.8026, device='cuda:0')\n",
      "tensor(2.6107, device='cuda:0')\n",
      "tensor(0.8114, device='cuda:0')\n",
      "tensor(2.6654, device='cuda:0')\n",
      "tensor(1.0361, device='cuda:0')\n",
      "tensor(2.9497, device='cuda:0')\n",
      "tensor(1.0513, device='cuda:0')\n",
      "tensor(3.0183, device='cuda:0')\n",
      "tensor(1.1098, device='cuda:0')\n",
      "tensor(3.1742, device='cuda:0')\n",
      "tensor(1.1594, device='cuda:0')\n",
      "tensor(3.3008, device='cuda:0')\n",
      "tensor(1.1718, device='cuda:0')\n",
      "tensor(3.3769, device='cuda:0')\n",
      "tensor(1.4655, device='cuda:0')\n",
      "tensor(3.6773, device='cuda:0')\n",
      "tensor(1.4748, device='cuda:0')\n",
      "tensor(3.7363, device='cuda:0')\n",
      "tensor(1.6720, device='cuda:0')\n",
      "tensor(4.0198, device='cuda:0')\n",
      "tensor(1.6780, device='cuda:0')\n",
      "tensor(4.0841, device='cuda:0')\n",
      "tensor(1.7100, device='cuda:0')\n",
      "tensor(4.2193, device='cuda:0')\n",
      "tensor(1.7336, device='cuda:0')\n",
      "tensor(4.3213, device='cuda:0')\n",
      "tensor(1.7406, device='cuda:0')\n",
      "tensor(4.3766, device='cuda:0')\n",
      "tensor(1.7658, device='cuda:0')\n",
      "tensor(4.4949, device='cuda:0')\n",
      "tensor(1.7661, device='cuda:0')\n",
      "tensor(4.5304, device='cuda:0')\n",
      "tensor(1.8313, device='cuda:0')\n",
      "tensor(4.6151, device='cuda:0')\n",
      "tensor(1.8313, device='cuda:0')\n",
      "tensor(4.6503, device='cuda:0')\n",
      "tensor(1.8424, device='cuda:0')\n",
      "tensor(4.7194, device='cuda:0')\n",
      "time 0.51\n",
      "error 4.71940279006958\n",
      "tensor(1.8424, device='cuda:0')\n",
      "1   ReLU()\n",
      "{}\n",
      "2   Linear(in_features=784, out_features=784, bias=True)\n",
      "{}\n",
      "Linear(in_features=784, out_features=784, bias=True)\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "2 \n",
      "pruning ...\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "time 0.45\n",
      "error 0.0\n",
      "tensor(0., device='cuda:0')\n",
      "3   ReLU()\n",
      "{}\n",
      "4   Linear(in_features=784, out_features=784, bias=True)\n",
      "{}\n",
      "Linear(in_features=784, out_features=784, bias=True)\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "4 \n",
      "pruning ...\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "time 0.41\n",
      "error 0.0\n",
      "tensor(0., device='cuda:0')\n",
      "5   ReLU()\n",
      "{}\n",
      "6   Linear(in_features=784, out_features=784, bias=True)\n",
      "{}\n",
      "Linear(in_features=784, out_features=784, bias=True)\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "6 \n",
      "pruning ...\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "tensor(0.5989, device='cuda:0')\n",
      "tensor(5.7018, device='cuda:0')\n",
      "time 0.46\n",
      "error 5.70177698135376\n",
      "tensor(0.5989, device='cuda:0')\n",
      "7   ReLU()\n",
      "{}\n",
      "8   Linear(in_features=784, out_features=784, bias=True)\n",
      "{}\n",
      "Linear(in_features=784, out_features=784, bias=True)\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "8 \n",
      "pruning ...\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "time 0.44\n",
      "error 0.0\n",
      "tensor(0., device='cuda:0')\n",
      "9   ReLU()\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "mlp_sequential(model, calibration_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
