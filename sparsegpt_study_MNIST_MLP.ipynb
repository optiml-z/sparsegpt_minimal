{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\igor-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_runtime.py:185: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from modelutils import *\n",
    "from quant import *\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"block_dynamic_mnist_mlp.pth\"\n",
    "LOAD = True\n",
    "\n",
    "if not(LOAD):\n",
    "    SAVE = True\n",
    "else:\n",
    "    SAVE = False\n",
    "\n",
    "DEBUG = True \n",
    "\n",
    "@dataclass\n",
    "class Args(object):\n",
    "    nsamples: int = 16\n",
    "    sparsity = 0.3\n",
    "    prunen: int = 0\n",
    "    prunem: int = 0\n",
    "    percdamp = .01\n",
    "    blocksize: int = 16\n",
    "    batch_size: int = 64\n",
    "    num_layers: int = 4\n",
    "    input_size: int = 784\n",
    "    output_size: int = 10\n",
    "    minlayer: int = -1\n",
    "    maxlayer: int = 1000\n",
    "    prune_only: str = \"\"\n",
    "    invert: bool = True\n",
    "args = Args()\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preparation\n",
    "# Define transformations and load datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "# Confirm if data is loaded\n",
    "len(trainset), len(testset)\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCBlock(nn.Module):\n",
    "    def __init__(self, input_size = 28*28, output_size = 28*28):\n",
    "        super(FCBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(output_size, output_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=28*28, output_size=10, num_blocks = 4):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.layers = [FCBlock() for i in range(num_blocks)]\n",
    "        self.out = nn.Linear(input_size, output_size)\n",
    "        self.layers.append(self.out)\n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer(x)\n",
    "        return self.layers[-1](x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DynamicMLP(num_layers=args.num_layers).to(device)\n",
    "# model = BlockDynamicMLP(input_size=28*28, output_size=10, num_blocks=4, num_layers=args.num_layers).to(device)\n",
    "model = MLP().to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "train_losses, test_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-3): 4 x FCBlock(\n",
       "    (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (fc2): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (relu2): ReLU()\n",
       "  )\n",
       "  (4): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5.. Train loss: 0.857.. Test loss: 0.343.. Test accuracy: 0.907\n",
      "Epoch 2/5.. Train loss: 0.347.. Test loss: 0.300.. Test accuracy: 0.915\n",
      "Epoch 3/5.. Train loss: 0.275.. Test loss: 0.238.. Test accuracy: 0.939\n",
      "Epoch 4/5.. Train loss: 0.256.. Test loss: 0.254.. Test accuracy: 0.935\n",
      "Epoch 5/5.. Train loss: 0.217.. Test loss: 0.207.. Test accuracy: 0.948\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if LOAD:\n",
    "    PATH = f'./{MODEL_NAME}'\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "else:    \n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images.to(device))\n",
    "            loss = criterion(output, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        else:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in testloader:\n",
    "                    log_ps = model(images.to(device))\n",
    "                    test_loss += criterion(log_ps, labels.to(device))\n",
    "                    ps = torch.exp(log_ps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.to(device).view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                    \n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "            print(f\"Epoch {e+1}/{epochs}.. \"\n",
    "                f\"Train loss: {running_loss/len(trainloader):.3f}.. \"\n",
    "                f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "\n",
    "    print('Finished Training')\n",
    "    if SAVE:\n",
    "        PATH = f'./{MODEL_NAME}'\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        plt.plot(train_losses, label='Training loss')\n",
    "        plt.plot(list(map(torch.Tensor.cpu, test_losses)), label='Validation loss')\n",
    "        plt.legend(frameon=False)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples tested = 1000\n",
      "\n",
      "Model Accuracy = 0.688\n"
     ]
    }
   ],
   "source": [
    "def infer_and_compute_accuracy_random_samples(model, dataset, num_samples=1000):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    # Create a list of indices and shuffle them\n",
    "    indices = list(range(len(dataset)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num_samples]\n",
    "\n",
    "    # Create a DataLoader with SubsetRandomSampler\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    testloader_random_samples = DataLoader(dataset, batch_size=64, sampler=sampler)\n",
    "\n",
    "    correct_count, all_count = 0, 0\n",
    "    for images, labels in testloader_random_samples:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images.view(images.shape[0], -1).to(device))\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_count += (predicted == labels.to(device)).sum().item()\n",
    "        all_count += labels.size(0)\n",
    "    \n",
    "    print(\"Number of Samples tested =\", all_count)\n",
    "    print(\"\\nModel Accuracy =\", (correct_count / all_count))\n",
    "\n",
    "# Assuming testset is your test dataset\n",
    "# Call the function\n",
    "infer_and_compute_accuracy_random_samples(model, testset, num_samples=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1](torch.randn(1, 28*28).to(device)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-2): 3 x FCBlock(\n",
       "    (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (fc2): Linear(in_features=784, out_features=784, bias=True)\n",
       "    (relu2): ReLU()\n",
       "  )\n",
       "  (3): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseGPT:\n",
    "\n",
    "    def __init__(self, layer):\n",
    "        self.layer = layer\n",
    "        print(layer)\n",
    "        print(type(layer))\n",
    "        self.dev = self.layer.weight.device\n",
    "        W = layer.weight.data.clone()\n",
    "        if isinstance(self.layer, nn.Conv2d):\n",
    "            W = W.flatten(1)\n",
    "        if isinstance(self.layer, transformers.Conv1D):\n",
    "            W = W.t()\n",
    "        self.rows = W.shape[0]\n",
    "        self.columns = W.shape[1]\n",
    "        self.H = torch.zeros((self.columns, self.columns), device=self.dev)\n",
    "        self.nsamples = 0\n",
    "\n",
    "    def add_batch(self, inp, out, blocksize=1024):\n",
    "        if DEBUG:\n",
    "            self.inp1 = inp\n",
    "            self.out1 = out\n",
    "        if len(inp.shape) == 2:\n",
    "            inp = inp.unsqueeze(0)\n",
    "        tmp = inp.shape[0]\n",
    "        if isinstance(self.layer, nn.Linear) or isinstance(self.layer, transformers.Conv1D):\n",
    "            if len(inp.shape) == 3:\n",
    "                inp = inp.reshape((-1, inp.shape[-1]))\n",
    "            inp = inp.t()\n",
    "        self.H *= self.nsamples / (self.nsamples + tmp)\n",
    "        self.nsamples += tmp\n",
    "        inp = math.sqrt(2 / self.nsamples) * inp.float()\n",
    "        self.H += inp.matmul(inp.t())\n",
    "\n",
    "    def fasterprune(\n",
    "        self, sparsity, prunen=0, prunem=0, blocksize=128, percdamp=.01\n",
    "    ):\n",
    "        W = self.layer.weight.data.clone()\n",
    "        if isinstance(self.layer, nn.Conv2d):\n",
    "            W = W.flatten(1)\n",
    "        if isinstance(self.layer, transformers.Conv1D):\n",
    "            W = W.t()\n",
    "        W = W.float()\n",
    "\n",
    "        if hasattr(self, 'quantizer'):\n",
    "            if not self.quantizer.ready():\n",
    "                self.quantizer.find_params(W, weight=True)\n",
    "\n",
    "        tick = time.time()\n",
    "\n",
    "        H = self.H\n",
    "        del self.H\n",
    "        dead = torch.diag(H) == 0\n",
    "        H[dead, dead] = 1\n",
    "        W[:, dead] = 0\n",
    "\n",
    "        Losses = torch.zeros(self.rows, device=self.dev)\n",
    "\n",
    "        damp = percdamp * torch.mean(torch.diag(H))\n",
    "        diag = torch.arange(self.columns, device=self.dev)\n",
    "        H[diag, diag] += damp\n",
    "        H = torch.linalg.cholesky(H)\n",
    "        H = torch.cholesky_inverse(H)\n",
    "        H = torch.linalg.cholesky(H, upper=True)\n",
    "        Hinv = H\n",
    "\n",
    "        mask = None\n",
    "\n",
    "        for i1 in range(0, self.columns, blocksize):\n",
    "            i2 = min(i1 + blocksize, self.columns)\n",
    "            count = i2 - i1\n",
    "\n",
    "            W1 = W[:, i1:i2].clone()\n",
    "            Q1 = torch.zeros_like(W1)\n",
    "            Err1 = torch.zeros_like(W1)\n",
    "            Losses1 = torch.zeros_like(W1)\n",
    "            Hinv1 = Hinv[i1:i2, i1:i2]\n",
    "\n",
    "            if prunen == 0: \n",
    "                if mask is not None:\n",
    "                    mask1 = mask[:, i1:i2]\n",
    "                else:\n",
    "                    tmp = W1 ** 2 / (torch.diag(Hinv1).reshape((1, -1))) ** 2\n",
    "                    thresh = torch.sort(tmp.flatten())[0][int(tmp.numel() * sparsity)]\n",
    "                    mask1 = tmp <= thresh\n",
    "            else:\n",
    "                mask1 = torch.zeros_like(W1) == 1\n",
    "\n",
    "            for i in range(count):\n",
    "                w = W1[:, i]\n",
    "                d = Hinv1[i, i]\n",
    "\n",
    "                if prunen != 0 and i % prunem == 0:\n",
    "                    tmp = W1[:, i:(i + prunem)] ** 2 / (torch.diag(Hinv1)[i:(i + prunem)].reshape((1, -1))) ** 2\n",
    "                    mask1.scatter_(1, i + torch.topk(tmp, prunen, dim=1, largest=False)[1], True)\n",
    "\n",
    "                q = w.clone()\n",
    "                q[mask1[:, i]] = 0\n",
    "\n",
    "                if hasattr(self, 'quantizer'):\n",
    "                    q = quantize(\n",
    "                        q.unsqueeze(1), self.quantizer.scale, self.quantizer.zero, self.quantizer.maxq\n",
    "                    ).flatten()\n",
    "\n",
    "                Q1[:, i] = q\n",
    "                Losses1[:, i] = (w - q) ** 2 / d ** 2\n",
    "\n",
    "                err1 = (w - q) / d\n",
    "                W1[:, i:] -= err1.unsqueeze(1).matmul(Hinv1[i, i:].unsqueeze(0))\n",
    "                Err1[:, i] = err1\n",
    "\n",
    "            W[:, i1:i2] = Q1\n",
    "            Losses += torch.sum(Losses1, 1) / 2\n",
    "\n",
    "            W[:, i2:] -= Err1.matmul(Hinv[i1:i2, i2:])\n",
    "\n",
    "            if DEBUG:\n",
    "                self.layer.weight.data[:, :i2] = W[:, :i2]\n",
    "                self.layer.weight.data[:, i2:] = W[:, i2:]\n",
    "                print(torch.sum((self.layer(self.inp1) - self.out1) ** 2))\n",
    "                print(torch.sum(Losses))\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        print('time %.2f' % (time.time() - tick))\n",
    "        print('error', torch.sum(Losses).item())\n",
    "\n",
    "        if isinstance(self.layer, transformers.Conv1D):\n",
    "            W = W.t()\n",
    "        self.layer.weight.data = W.reshape(self.layer.weight.shape).to(self.layer.weight.data.dtype)\n",
    "        if DEBUG:\n",
    "            print(torch.sum((self.layer(self.inp1) - self.out1) ** 2))\n",
    "\n",
    "    def free(self):\n",
    "        if DEBUG:\n",
    "            self.inp1 = None\n",
    "            self.out1 = None\n",
    "        self.H = None\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def mlp_sequential(model, dataloader, dev):\n",
    "    print('Starting ...')\n",
    "\n",
    "    # use_cache = model.config.use_cache\n",
    "    # model.config.use_cache = False\n",
    "    # layers = model.transformer.h\n",
    "    layers = model.layers\n",
    "    print(\"layers: \", layers)\n",
    "    # model.transformer.word_embeddings = model.transformer.word_embeddings.to(dev)\n",
    "    # model.transformer.word_embeddings_layernorm = model.transformer.word_embeddings_layernorm.to(dev)\n",
    "    layers[0] = layers[0].to(dev)\n",
    "    \n",
    "    print(\"layers[0]: \", layers[0])\n",
    "    layers[0] = layers[0].to(dev)\n",
    "\n",
    "    dtype = next(iter(model.parameters())).dtype\n",
    "    inps = torch.zeros(\n",
    "        (args.nsamples, args.nsamples, 28*28), dtype=dtype, device=dev\n",
    "    )\n",
    "    # cache = {'i': 0, 'attention_mask': None, 'alibi': None}\n",
    "    cache = {'i': 0}\n",
    "\n",
    "    class Catcher(nn.Module):\n",
    "        def __init__(self, module):\n",
    "            super().__init__()\n",
    "            self.module = module\n",
    "        def forward(self, inp, **kwargs):\n",
    "            # print(\"inps cache: \", inps[cache['i']])\n",
    "            # if cache['i'] == args.nsamples - 1:\n",
    "            #     raise ValueError\n",
    "            if cache['i'] < args.nsamples:\n",
    "                inps[cache['i']] = inp\n",
    "                cache['i'] += 1\n",
    "            # cache['attention_mask'] = kwargs['attention_mask']\n",
    "            # cache['alibi'] = kwargs['alibi']\n",
    "            raise ValueError\n",
    "    layers[0] = Catcher(layers[0])\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        try:\n",
    "            # print(i)\n",
    "            # print(batch[0].shape)\n",
    "            model(batch[0].to(dev))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    layers[0] = layers[0].module\n",
    "\n",
    "    layers[0] = layers[0].cpu()\n",
    "    # model.transformer.word_embeddings = model.transformer.word_embeddings.cpu()\n",
    "    # model.transformer.word_embeddings_layernorm = model.transformer.word_embeddings_layernorm.cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    outs = torch.zeros_like(inps)\n",
    "    # attention_mask = cache['attention_mask']\n",
    "    # alibi = cache['alibi']\n",
    "\n",
    "    print('Ready.')\n",
    "\n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i].to(dev)\n",
    "\n",
    "        subset = find_layers(layer)\n",
    "        gpts = {}\n",
    "        for name in subset:\n",
    "            if (not (args.minlayer <= i < args.maxlayer and args.prune_only in name)) == (not args.invert):\n",
    "                continue\n",
    "            gpts[name] = SparseGPT(subset[name])\n",
    "\n",
    "        def add_batch(name):\n",
    "            def tmp(_, inp, out):\n",
    "                gpts[name].add_batch(inp[0].data, out.data)\n",
    "            return tmp\n",
    "        handles = []\n",
    "        for name in gpts:\n",
    "            handles.append(subset[name].register_forward_hook(add_batch(name)))\n",
    "        for j in range(args.nsamples):\n",
    "            # outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask, alibi=alibi)[0]\n",
    "            outs[j] = layer(inps[j].unsqueeze(0))[0]\n",
    "        for h in handles:\n",
    "            h.remove()\n",
    "\n",
    "        for name in gpts:\n",
    "            print(i, name)\n",
    "            print('pruning ...')\n",
    "            gpts[name].fasterprune(\n",
    "                args.sparsity, prunen=args.prunen, prunem=args.prunem, percdamp=args.percdamp\n",
    "            )\n",
    "        for j in range(args.nsamples):\n",
    "            # outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask, alibi=alibi)[0]\n",
    "            outs[j] = layer(inps[j].unsqueeze(0))[0]\n",
    "\n",
    "        layers[i] = layer.cpu()\n",
    "        del gpts \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        inps, outs = outs, inps\n",
    "\n",
    "    # model.config.use_cache = use_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCBlock(\n",
       "  (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=784, out_features=784, bias=True)\n",
       "  (relu2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ...\n",
      "layers:  ModuleList(\n",
      "  (0): Catcher(\n",
      "    (module): Catcher(\n",
      "      (module): Catcher(\n",
      "        (module): FCBlock(\n",
      "          (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
      "          (relu1): ReLU()\n",
      "          (fc2): Linear(in_features=784, out_features=784, bias=True)\n",
      "          (relu2): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1-3): 3 x FCBlock(\n",
      "    (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (fc2): Linear(in_features=784, out_features=784, bias=True)\n",
      "    (relu2): ReLU()\n",
      "  )\n",
      "  (4): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "layers[0]:  Catcher(\n",
      "  (module): Catcher(\n",
      "    (module): Catcher(\n",
      "      (module): FCBlock(\n",
      "        (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
      "        (relu1): ReLU()\n",
      "        (fc2): Linear(in_features=784, out_features=784, bias=True)\n",
      "        (relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.cuda.FloatTensor{[16, 784]}, size=[784]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmlp_sequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\igor-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[21], line 43\u001b[0m, in \u001b[0;36mmlp_sequential\u001b[1;34m(model, dataloader, dev)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;66;03m# print(i)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;66;03m# print(batch[0].shape)\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\igor-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[4], line 31\u001b[0m, in \u001b[0;36mMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m---> 31\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m](x)\n",
      "File \u001b[1;32mc:\\Users\\igor-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[21], line 33\u001b[0m, in \u001b[0;36mmlp_sequential.<locals>.Catcher.forward\u001b[1;34m(self, inp, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# print(\"inps cache: \", inps[cache['i']])\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# if cache['i'] == args.nsamples - 1:\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m#     raise ValueError\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# if cache['i'] < args.nsamples:\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     \u001b[43minps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m inp\n\u001b[0;32m     34\u001b[0m     cache[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# cache['attention_mask'] = kwargs['attention_mask']\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# cache['alibi'] = kwargs['alibi']\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expand(torch.cuda.FloatTensor{[16, 784]}, size=[784]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)"
     ]
    }
   ],
   "source": [
    "mlp_sequential(model, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
