{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\igor-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_runtime.py:185: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from modelutils import *\n",
    "from quant import *\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"dynamic_mnist_mlp.pth\"\n",
    "LOAD = True\n",
    "\n",
    "if not(LOAD):\n",
    "    SAVE = True\n",
    "else:\n",
    "    SAVE = False\n",
    "\n",
    "DEBUG = True \n",
    "\n",
    "@dataclass\n",
    "class Args(object):\n",
    "    nsamples: int = 8\n",
    "    sparsity = 0.3\n",
    "    prunen: int = 0\n",
    "    prunem: int = 0\n",
    "    percdamp = .01\n",
    "    blocksize: int = 4\n",
    "    batch_size: int = 8\n",
    "    num_layers: int = 5\n",
    "    input_size: int = 784\n",
    "    output_size: int = 10\n",
    "    \n",
    "args = Args()\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preparation\n",
    "# Define transformations and load datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "# Confirm if data is loaded\n",
    "len(trainset), len(testset)\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 8     6     6     9     0     0     7     6    \n"
     ]
    }
   ],
   "source": [
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'\\n {classes[labels[j]]:5s}' if j%8 == 0 else ''.join(f'{classes[labels[j]]:5s}') for j in range(args.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicMLP(nn.Module):\n",
    "    def __init__(self, input_size=28*28, output_size=10, hidden_sizes=0, num_layers=5):\n",
    "        super(DynamicMLP, self).__init__()\n",
    "        \n",
    "        # Ensure hidden_sizes is a list for consistency\n",
    "        if not isinstance(hidden_sizes, list):\n",
    "            hidden_sizes = [input_size] * num_layers\n",
    "        elif len(hidden_sizes) == 0:\n",
    "            hidden_sizes += [input_size] * (num_layers - len(hidden_sizes))\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        # Input layer\n",
    "        layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i in range(1, num_layers):\n",
    "            layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[min(i, len(hidden_sizes)-1)]))\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        \n",
    "        # ModuleList to hold all layers\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply each layer with ReLU activation, except for the output layer\n",
    "        x = x.view(-1, 28*28) # Flatten the image        \n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "        # Output layer without ReLU activation\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "    \n",
    "class MLPSeq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPSeq, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(28**2, 28**2) for i in range(5)])        \n",
    "        # self.linears.insert(0, nn.Flatten())\n",
    "        # self.fc_block1 = nn.Sequential(\n",
    "        #     nn.Linear(28*28, 28*28),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(28*28, 28*28),\n",
    "        #     nn.ReLU(),\n",
    "        # )\n",
    "        # self.fc_block2 = nn.Sequential(\n",
    "        #     nn.Linear(28*28, 28*28),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(28*28, 28*28),\n",
    "        #     nn.ReLU(),\n",
    "        # )\n",
    "        self.out = nn.Linear(28*28, 10)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) # Flatten the image\n",
    "        for layer in self.linears:\n",
    "            x = torch.relu(layer(x))\n",
    "        # x = self.fc_block1(x)\n",
    "        # x = self.fc_block2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DynamicMLP(num_layers=args.num_layers).to(device)\n",
    "# model = MLPSeq().to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 1\n",
    "train_losses, test_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD:\n",
    "    PATH = f'./{MODEL_NAME}'\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "else:    \n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images.to(device))\n",
    "            loss = criterion(output, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        else:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in testloader:\n",
    "                    log_ps = model(images.to(device))\n",
    "                    test_loss += criterion(log_ps, labels.to(device))\n",
    "                    ps = torch.exp(log_ps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.to(device).view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                    \n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "            print(f\"Epoch {e+1}/{epochs}.. \"\n",
    "                f\"Train loss: {running_loss/len(trainloader):.3f}.. \"\n",
    "                f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "\n",
    "    print('Finished Training')\n",
    "    if SAVE:\n",
    "        PATH = f'./{MODEL_NAME}'\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        plt.plot(train_losses, label='Training loss')\n",
    "        plt.plot(list(map(torch.Tensor.cpu, test_losses)), label='Validation loss')\n",
    "        plt.legend(frameon=False)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples tested = 1000\n",
      "\n",
      "Model Accuracy = 0.918\n"
     ]
    }
   ],
   "source": [
    "def infer_and_compute_accuracy_random_samples(model, dataset, num_samples=1000):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    # Create a list of indices and shuffle them\n",
    "    indices = list(range(len(dataset)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num_samples]\n",
    "\n",
    "    # Create a DataLoader with SubsetRandomSampler\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    testloader_random_samples = DataLoader(dataset, batch_size=64, sampler=sampler)\n",
    "\n",
    "    correct_count, all_count = 0, 0\n",
    "    for images, labels in testloader_random_samples:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images.view(images.shape[0], -1).to(device))\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_count += (predicted == labels.to(device)).sum().item()\n",
    "        all_count += labels.size(0)\n",
    "    \n",
    "    print(\"Number of Samples tested =\", all_count)\n",
    "    print(\"\\nModel Accuracy =\", (correct_count / all_count))\n",
    "\n",
    "# Assuming testset is your test dataset\n",
    "# Call the function\n",
    "infer_and_compute_accuracy_random_samples(model, testset, num_samples=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1](torch.randn(1, 28*28).to(device)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseGPT:\n",
    "\n",
    "    def __init__(self, layer):\n",
    "        self.layer = layer\n",
    "        print(layer)\n",
    "        print(type(layer))\n",
    "        self.dev = self.layer.weight.device\n",
    "        W = layer.weight.data.clone()\n",
    "        if isinstance(self.layer, nn.Conv2d):\n",
    "            W = W.flatten(1)\n",
    "        if isinstance(self.layer, transformers.Conv1D):\n",
    "            W = W.t()\n",
    "        self.rows = W.shape[0]\n",
    "        self.columns = W.shape[1]\n",
    "        self.H = torch.zeros((self.columns, self.columns), device=self.dev)\n",
    "        self.nsamples = 0\n",
    "\n",
    "    def add_batch(self, inp, out, blocksize=1024):\n",
    "        if DEBUG:\n",
    "            self.inp1 = inp\n",
    "            self.out1 = out\n",
    "        if len(inp.shape) == 2:\n",
    "            inp = inp.unsqueeze(0)\n",
    "        tmp = inp.shape[0]\n",
    "        if isinstance(self.layer, nn.Linear) or isinstance(self.layer, transformers.Conv1D):\n",
    "            if len(inp.shape) == 3:\n",
    "                inp = inp.reshape((-1, inp.shape[-1]))\n",
    "            inp = inp.t()\n",
    "        self.H *= self.nsamples / (self.nsamples + tmp)\n",
    "        self.nsamples += tmp\n",
    "        inp = math.sqrt(2 / self.nsamples) * inp.float()\n",
    "        self.H += inp.matmul(inp.t())\n",
    "\n",
    "    def fasterprune(\n",
    "        self, sparsity, prunen=0, prunem=0, blocksize=128, percdamp=.01\n",
    "    ):\n",
    "        W = self.layer.weight.data.clone()\n",
    "        if isinstance(self.layer, nn.Conv2d):\n",
    "            W = W.flatten(1)\n",
    "        if isinstance(self.layer, transformers.Conv1D):\n",
    "            W = W.t()\n",
    "        W = W.float()\n",
    "\n",
    "        if hasattr(self, 'quantizer'):\n",
    "            if not self.quantizer.ready():\n",
    "                self.quantizer.find_params(W, weight=True)\n",
    "\n",
    "        tick = time.time()\n",
    "\n",
    "        H = self.H\n",
    "        del self.H\n",
    "        dead = torch.diag(H) == 0\n",
    "        H[dead, dead] = 1\n",
    "        W[:, dead] = 0\n",
    "\n",
    "        Losses = torch.zeros(self.rows, device=self.dev)\n",
    "\n",
    "        damp = percdamp * torch.mean(torch.diag(H))\n",
    "        diag = torch.arange(self.columns, device=self.dev)\n",
    "        H[diag, diag] += damp\n",
    "        H = torch.linalg.cholesky(H)\n",
    "        H = torch.cholesky_inverse(H)\n",
    "        H = torch.linalg.cholesky(H, upper=True)\n",
    "        Hinv = H\n",
    "\n",
    "        mask = None\n",
    "\n",
    "        for i1 in range(0, self.columns, blocksize):\n",
    "            i2 = min(i1 + blocksize, self.columns)\n",
    "            count = i2 - i1\n",
    "\n",
    "            W1 = W[:, i1:i2].clone()\n",
    "            Q1 = torch.zeros_like(W1)\n",
    "            Err1 = torch.zeros_like(W1)\n",
    "            Losses1 = torch.zeros_like(W1)\n",
    "            Hinv1 = Hinv[i1:i2, i1:i2]\n",
    "\n",
    "            if prunen == 0: \n",
    "                if mask is not None:\n",
    "                    mask1 = mask[:, i1:i2]\n",
    "                else:\n",
    "                    tmp = W1 ** 2 / (torch.diag(Hinv1).reshape((1, -1))) ** 2\n",
    "                    thresh = torch.sort(tmp.flatten())[0][int(tmp.numel() * sparsity)]\n",
    "                    mask1 = tmp <= thresh\n",
    "            else:\n",
    "                mask1 = torch.zeros_like(W1) == 1\n",
    "\n",
    "            for i in range(count):\n",
    "                w = W1[:, i]\n",
    "                d = Hinv1[i, i]\n",
    "\n",
    "                if prunen != 0 and i % prunem == 0:\n",
    "                    tmp = W1[:, i:(i + prunem)] ** 2 / (torch.diag(Hinv1)[i:(i + prunem)].reshape((1, -1))) ** 2\n",
    "                    mask1.scatter_(1, i + torch.topk(tmp, prunen, dim=1, largest=False)[1], True)\n",
    "\n",
    "                q = w.clone()\n",
    "                q[mask1[:, i]] = 0\n",
    "\n",
    "                if hasattr(self, 'quantizer'):\n",
    "                    q = quantize(\n",
    "                        q.unsqueeze(1), self.quantizer.scale, self.quantizer.zero, self.quantizer.maxq\n",
    "                    ).flatten()\n",
    "\n",
    "                Q1[:, i] = q\n",
    "                Losses1[:, i] = (w - q) ** 2 / d ** 2\n",
    "\n",
    "                err1 = (w - q) / d\n",
    "                W1[:, i:] -= err1.unsqueeze(1).matmul(Hinv1[i, i:].unsqueeze(0))\n",
    "                Err1[:, i] = err1\n",
    "\n",
    "            W[:, i1:i2] = Q1\n",
    "            Losses += torch.sum(Losses1, 1) / 2\n",
    "\n",
    "            W[:, i2:] -= Err1.matmul(Hinv[i1:i2, i2:])\n",
    "\n",
    "            if DEBUG:\n",
    "                self.layer.weight.data[:, :i2] = W[:, :i2]\n",
    "                self.layer.weight.data[:, i2:] = W[:, i2:]\n",
    "                print(torch.sum((self.layer(self.inp1) - self.out1) ** 2))\n",
    "                print(torch.sum(Losses))\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        print('time %.2f' % (time.time() - tick))\n",
    "        print('error', torch.sum(Losses).item())\n",
    "\n",
    "        if isinstance(self.layer, transformers.Conv1D):\n",
    "            W = W.t()\n",
    "        self.layer.weight.data = W.reshape(self.layer.weight.shape).to(self.layer.weight.data.dtype)\n",
    "        if DEBUG:\n",
    "            print(torch.sum((self.layer(self.inp1) - self.out1) ** 2))\n",
    "\n",
    "    def free(self):\n",
    "        if DEBUG:\n",
    "            self.inp1 = None\n",
    "            self.out1 = None\n",
    "        self.H = None\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DynamicMLP(num_layers=args.num_layers).to(device)\n",
    "@torch.no_grad()\n",
    "def mlp_sequential(model, dataloader, dev):\n",
    "    print('Starting ...')\n",
    "\n",
    "    # use_cache = model.config.use_cache\n",
    "    # model.config.use_cache = False\n",
    "    # layers = model.transformer.h\n",
    "    layers = model.layers\n",
    "    print(\"layers: \", layers)\n",
    "    # model.transformer.word_embeddings = model.transformer.word_embeddings.to(dev)\n",
    "    # model.transformer.word_embeddings_layernorm = model.transformer.word_embeddings_layernorm.to(dev)\n",
    "    layers[0] = layers[0].to(dev)\n",
    "    \n",
    "    print(\"layers[0]: \", layers[0])\n",
    "    layers[0] = layers[0].to(dev)\n",
    "\n",
    "    dtype = next(iter(model.parameters())).dtype\n",
    "    inps = torch.zeros(\n",
    "        (args.nsamples, args.batch_size, 28*28), dtype=dtype, device=dev\n",
    "    )\n",
    "    # cache = {'i': 0, 'attention_mask': None, 'alibi': None}\n",
    "    cache = {'i': 0}\n",
    "\n",
    "    class Catcher(nn.Module):\n",
    "        def __init__(self, module):\n",
    "            super().__init__()\n",
    "            self.module = module\n",
    "        def forward(self, inp, **kwargs):\n",
    "            # print(\"inps cache: \", inps[cache['i']])\n",
    "            inps[cache['i']] = inp\n",
    "            cache['i'] += 1\n",
    "            # cache['attention_mask'] = kwargs['attention_mask']\n",
    "            # cache['alibi'] = kwargs['alibi']\n",
    "            raise ValueError\n",
    "    layers[0] = Catcher(layers[0])\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        try:\n",
    "            print(i)\n",
    "            print(batch[0].shape)\n",
    "            model(batch[0].to(dev))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    layers[0] = layers[0].module\n",
    "\n",
    "    layers[0] = layers[0].cpu()\n",
    "    # model.transformer.word_embeddings = model.transformer.word_embeddings.cpu()\n",
    "    # model.transformer.word_embeddings_layernorm = model.transformer.word_embeddings_layernorm.cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    outs = torch.zeros_like(inps)\n",
    "    # attention_mask = cache['attention_mask']\n",
    "    # alibi = cache['alibi']\n",
    "\n",
    "    print('Ready.')\n",
    "\n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i].to(dev)\n",
    "\n",
    "        subset = find_layers(layer)\n",
    "        gpts = {}\n",
    "        for name in subset:\n",
    "            if (not (args.minlayer <= i < args.maxlayer and args.prune_only in name)) == (not args.invert):\n",
    "                continue\n",
    "            gpts[name] = SparseGPT(subset[name])\n",
    "\n",
    "        def add_batch(name):\n",
    "            def tmp(_, inp, out):\n",
    "                gpts[name].add_batch(inp[0].data, out.data)\n",
    "            return tmp\n",
    "        handles = []\n",
    "        for name in gpts:\n",
    "            handles.append(subset[name].register_forward_hook(add_batch(name)))\n",
    "        for j in range(args.nsamples):\n",
    "            # outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask, alibi=alibi)[0]\n",
    "            outs[j] = layer(inps[j].unsqueeze(0))[0]\n",
    "        for h in handles:\n",
    "            h.remove()\n",
    "\n",
    "        for name in gpts:\n",
    "            print(i, name)\n",
    "            print('pruning ...')\n",
    "            gpts[name].fasterprune(\n",
    "                args.sparsity, prunen=args.prunen, prunem=args.prunem, percdamp=args.percdamp\n",
    "            )\n",
    "        for j in range(args.nsamples):\n",
    "            # outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask, alibi=alibi)[0]\n",
    "            outs[j] = layer(inps[j].unsqueeze(0))[0]\n",
    "\n",
    "        layers[i] = layer.cpu()\n",
    "        del gpts \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        inps, outs = outs, inps\n",
    "\n",
    "    # model.config.use_cache = use_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ...\n",
      "layers:  ModuleList(\n",
      "  (0-4): 5 x Linear(in_features=784, out_features=784, bias=True)\n",
      "  (5): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "layers[0]:  Linear(in_features=784, out_features=784, bias=True)\n",
      "0\n",
      "torch.Size([8, 1, 28, 28])\n",
      "1\n",
      "torch.Size([8, 1, 28, 28])\n",
      "2\n",
      "torch.Size([8, 1, 28, 28])\n",
      "3\n",
      "torch.Size([8, 1, 28, 28])\n",
      "4\n",
      "torch.Size([8, 1, 28, 28])\n",
      "5\n",
      "torch.Size([8, 1, 28, 28])\n",
      "6\n",
      "torch.Size([8, 1, 28, 28])\n",
      "7\n",
      "torch.Size([8, 1, 28, 28])\n",
      "8\n",
      "torch.Size([8, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for dimension 0 with size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmlp_sequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\igor-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[12], line 41\u001b[0m, in \u001b[0;36mmlp_sequential\u001b[1;34m(model, dataloader, dev)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 41\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\igor-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[6], line 30\u001b[0m, in \u001b[0;36mDynamicMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m) \u001b[38;5;66;03m# Flatten the image        \u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Output layer without ReLU activation\u001b[39;00m\n\u001b[0;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m](x)\n",
      "File \u001b[1;32mc:\\Users\\igor-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[12], line 31\u001b[0m, in \u001b[0;36mmlp_sequential.<locals>.Catcher.forward\u001b[1;34m(self, inp, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# print(\"inps cache: \", inps[cache['i']])\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     \u001b[43minps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m inp\n\u001b[0;32m     32\u001b[0m     cache[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# cache['attention_mask'] = kwargs['attention_mask']\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# cache['alibi'] = kwargs['alibi']\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 8 is out of bounds for dimension 0 with size 8"
     ]
    }
   ],
   "source": [
    "mlp_sequential(model, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def mlp_sequential(model, dataloader, dev):\n",
    "    print('Starting ...')\n",
    "\n",
    "    # use_cache = model.config.use_cache\n",
    "    # model.config.use_cache = False\n",
    "    \n",
    "    layers = list(model.modules())[0]\n",
    "    \n",
    "    print(layers)\n",
    "    layers = layers.to(dev)\n",
    "    layers_dict = find_layers(layers); print(layers_dict)\n",
    "    dtype = next(iter(model.parameters())).dtype\n",
    "    inps = torch.zeros(\n",
    "        (args.batch_size, 28*28), dtype=dtype, device=dev\n",
    "    )\n",
    "\n",
    "    for batch in dataloader:\n",
    "        try:\n",
    "            model(batch[0].to(dev))\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    outs = torch.zeros_like(inps)\n",
    "    # attention_mask = cache['attention_mask']\n",
    "\n",
    "    print('Ready.')\n",
    "    gpts = {}\n",
    "    for i, (layer_name, layer_obj) in enumerate(layers_dict.items()):\n",
    "        if i == len(layers_dict) - 1:\n",
    "            break\n",
    "        layer = layer_obj.to(dev)\n",
    "\n",
    "        # subset = find_layers(layer)\n",
    "        \n",
    "        # gpts = {}\n",
    "        # for name in subset:\n",
    "        gpts[layer_name] = SparseGPT(layer_obj)\n",
    "        print(\"layer_obj \", layer_obj)\n",
    "        def add_batch(layer_name):\n",
    "            def tmp(_, inp, out):\n",
    "                gpts[layer_name].add_batch(inp[0].data, out.data)\n",
    "            return tmp\n",
    "        handles = []\n",
    "        \n",
    "        handles.append(layer_obj.register_forward_hook(add_batch(layer_name)))\n",
    "        for j in range(args.batch_size):\n",
    "            # outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask)[0]\n",
    "            outs[j] = layer(inps[j].unsqueeze(0))[0]\n",
    "        for h in handles:\n",
    "            h.remove()\n",
    "\n",
    "        \n",
    "        print(layer_name)\n",
    "        print('Pruning ...')\n",
    "        sparsity = args.sparsity\n",
    "        gpts[layer_name].fasterprune(\n",
    "                sparsity, prunen=args.prunen, prunem=args.prunem, percdamp=args.percdamp, blocksize=args.blocksize\n",
    "            )\n",
    "        gpts[layer_name].free()\n",
    "\n",
    "        for j in range(args.batch_size):\n",
    "            # outs[j] = layer(inps[j].unsqueeze(0), attention_mask=attention_mask)[0]\n",
    "            outs[j] = layer(inps[j].unsqueeze(0))[0]\n",
    "\n",
    "        layer = layer.cpu()\n",
    "        del layer\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        inps, outs = outs, inps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ...\n",
      "DynamicMLP(\n",
      "  (layers): ModuleList(\n",
      "    (0-4): 5 x Linear(in_features=784, out_features=784, bias=True)\n",
      "    (5): Linear(in_features=784, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "{'layers.0': Linear(in_features=784, out_features=784, bias=True), 'layers.1': Linear(in_features=784, out_features=784, bias=True), 'layers.2': Linear(in_features=784, out_features=784, bias=True), 'layers.3': Linear(in_features=784, out_features=784, bias=True), 'layers.4': Linear(in_features=784, out_features=784, bias=True), 'layers.5': Linear(in_features=784, out_features=10, bias=True)}\n",
      "Ready.\n",
      "Linear(in_features=784, out_features=784, bias=True)\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "layer_obj  Linear(in_features=784, out_features=784, bias=True)\n",
      "layers.0\n",
      "Pruning ...\n",
      "time 1.52\n",
      "error 0.0\n",
      "Linear(in_features=784, out_features=784, bias=True)\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "layer_obj  Linear(in_features=784, out_features=784, bias=True)\n",
      "layers.1\n",
      "Pruning ...\n",
      "time 0.40\n",
      "error 6.331102486001328e-05\n",
      "Linear(in_features=784, out_features=784, bias=True)\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "layer_obj  Linear(in_features=784, out_features=784, bias=True)\n",
      "layers.2\n",
      "Pruning ...\n",
      "time 0.40\n",
      "error 0.0017441394738852978\n",
      "Linear(in_features=784, out_features=784, bias=True)\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "layer_obj  Linear(in_features=784, out_features=784, bias=True)\n",
      "layers.3\n",
      "Pruning ...\n",
      "time 0.40\n",
      "error 0.04572782665491104\n",
      "Linear(in_features=784, out_features=784, bias=True)\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "layer_obj  Linear(in_features=784, out_features=784, bias=True)\n",
      "layers.4\n",
      "Pruning ...\n",
      "time 0.40\n",
      "error 1.1236212253570557\n"
     ]
    }
   ],
   "source": [
    "mlp_sequential(model, testloader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
